{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'User experience (UX) and user interface (UI) designers are in high demand because they play a critical role in how people interact with technology'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('uiux_reason.txt') as file:\n",
    "    original = file.read().split('.')\n",
    "corpus = original\n",
    "corpus[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "# Remove Punctuation\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r\"[.?!,;:-]\", \" \", text)\n",
    "    text = re.sub(r'[^\\w\\s]', \"\", text)\n",
    "    text = re.sub(' +', \" \", text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Remove Stopwords\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word.lower()\n",
    "                      for word in text.split() if word.lower() not in stop]\n",
    "    if filtered_words != []:\n",
    "        return \" \".join(filtered_words)\n",
    "    else:\n",
    "        return(text)\n",
    "\n",
    "\n",
    "# Get word Tag\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Word lemmatization\n",
    "\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged_sent = pos_tag(tokens)\n",
    "\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmas_sent = []\n",
    "    for tag in tagged_sent:\n",
    "        wordnet_pos = get_wordnet_pos(tag[1]) or wordnet.NOUN\n",
    "        lemmas_sent.append(wnl.lemmatize(tag[0], pos=wordnet_pos))  # 詞形還原\n",
    "\n",
    "    return ' '.join(lemmas_sent)\n",
    "\n",
    "\n",
    "def sentence_processing(sentence):\n",
    "    sentence = remove_punctuation(sentence)\n",
    "    sentence = remove_stopwords(sentence)\n",
    "    sentence = lemmatize_sentence(sentence)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user experience ux user interface ui designer high demand play critical role people interact technology'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [sentence_processing(sentence) for sentence in corpus]\n",
    "corpus[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TFIDF Score Vectorize Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize = CountVectorizer()\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "# Use TFIDE Score of each words to build sentences Vector (sentences, unique words)\n",
    "tf_result = transformer.fit_transform(\n",
    "    vectorize.fit_transform(corpus)).toarray().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Representative Score of sentence by Counting average Cosine Similarity with all vectors\n",
    "def scoring(main, all):  \n",
    "    sum = 0\n",
    "    main = np.array(main).reshape(1, -1)\n",
    "    all = np.array(all)\n",
    "\n",
    "    for i in all:\n",
    "        sum += cosine_similarity(main, i.reshape(1, -1))\n",
    "    avg = sum / len(all)\n",
    "    return avg\n",
    "\n",
    "\n",
    "# List with Representative Score from highest to lowest\n",
    "def get_Score_refer(corpus, tf_result):\n",
    "\n",
    "    score_frame = []\n",
    "\n",
    "    for main in tf_result:\n",
    "        main_score = scoring(main, tf_result)\n",
    "        score_frame.append(main_score[0][0])\n",
    "\n",
    "    score_refer = list(zip(score_frame, tf_result, corpus))\n",
    "    score_refer.sort(key=lambda y: y[0], reverse=True)\n",
    "\n",
    "    return score_refer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text :\u001b[0;33;40m  They design how the product looks, making sure that it is visually appealing and easy to navigate\u001b[0m\n",
      "Original Text:  They design how the product looks, making sure that it is visually appealing and easy to navigate\n",
      "Similarity of All : \u001b[0;34;40m0.0666\u001b[0m\n",
      "Qulified Score : 0.0\n",
      "\n",
      "Text :\u001b[0;33;40m  They take into account how users interact with a product, what they need and want from it, and how they would like it to work\u001b[0m\n",
      "Original Text:  They take into account how users interact with a product, what they need and want from it, and how they would like it to work\n",
      "Similarity of All : \u001b[0;34;40m0.0666\u001b[0m\n",
      "Qulified Score : 0.04046643076267294\n",
      "\n",
      "Text :\u001b[0;33;40m  In addition, they are able to communicate with developers to ensure that the final product meets the requirements of both the users and the business\u001b[0m\n",
      "Original Text:  In addition, they are able to communicate with developers to ensure that the final product meets the requirements of both the users and the business\n",
      "Similarity of All : \u001b[0;34;40m0.0604\u001b[0m\n",
      "Qulified Score : 0.0462026105793951\n",
      "\n",
      "Text :\u001b[0;33;40m \n",
      "\n",
      "They are also in high demand because they are willing to learn new things and keep up with the latest trends\u001b[0m\n",
      "Original Text: \n",
      "\n",
      "They are also in high demand because they are willing to learn new things and keep up with the latest trends\n",
      "Similarity of All : \u001b[0;34;40m0.0601\u001b[0m\n",
      "Qulified Score : 0.026904683351967797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# return tfidf vector & text of highest similarity sentence to all sentences\n",
    "score_refer = get_Score_refer(corpus, tf_result)\n",
    "\n",
    "summa_list = [score_refer[0][2]]\n",
    "versus = [np.array(score_refer[0][1])]\n",
    "topics = 0\n",
    "for i in range(len(corpus)):\n",
    "    if topics <= 3:\n",
    "        present_chosen = np.array(score_refer[i][1]).reshape(1, -1)\n",
    "        qual_score = 0\n",
    "        for former_chosen in versus:\n",
    "            former_chosen = np.array(former_chosen).reshape(1, -1)\n",
    "            qual_score += cosine_similarity(present_chosen, former_chosen)\n",
    "\n",
    "        qual_score = qual_score / len(versus)\n",
    "\n",
    "        # if present sentences too similar with former sentence than reject it.\n",
    "        if qual_score[0][0] <= score_refer[i][0] and qual_score[0][0] <= 0.05:\n",
    "            text = score_refer[i][2]\n",
    "            original_text = original[int(corpus.index(f'{text}'))]\n",
    "\n",
    "            print(\n",
    "                f'Text :\\033[0;33;40m {text}\\033[0m'.format(text),\n",
    "                f'Original Text: {original_text}',\n",
    "                f'Similarity of All : \\033[0;34;40m{round(score_refer[i][0],4)}\\033[0m',\n",
    "                f'Qulified Score : {qual_score[0][0]}',\n",
    "                '',\n",
    "                sep='\\n')\n",
    "\n",
    "            summa_list.append(score_refer[i][2])\n",
    "            versus.append(score_refer[i][1])\n",
    "            topics += 1\n",
    "\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
